{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Retargeting via Deformation Fields\n",
    "In this notebook, you train the required models for retargeting an image from scratch. You can find the results of this notebook applied to the image `scenes/balloons.jpg` resized to 50% and 150% of the width in the directory `results`.\n",
    "\n",
    "__Note__: This code version is intended to be compact.\n",
    "\n",
    "To train on your own image, drop it in the `scenes` directory and adapt the `SCENE` parameter in the user input cell below. You can also choose any other resizing factor (0.5 stands for resizing to 50% of the image width, while 1.5 stands for resizing to 150% of the image width).\n",
    "\n",
    "Then, simply rerun the entire notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "###############  USER INPUTS  ###############\n",
    "#############################################\n",
    "\n",
    "SCENE = \"balloons\"      # write the name of your image without the file ending\n",
    "STRETCH_FACTOR = 0.5    # how much to stretch the image in the x-direction. 0.5 means half as wide, 2.0 means twice as wide\n",
    "DOWNSCALE_FACTOR = 2    # adjust the resolution of the initial image; > 1.0 means downscaling, < 1.0 means upscaling\n",
    "VISUALIZE = True        # if True, the intermediate steps of the algorithm are visualized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "#################  IMPORTS  #################\n",
    "#############################################\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.parallel\n",
    "import torch.utils.data\n",
    "\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "import imageio\n",
    "from PIL import Image\n",
    "\n",
    "import models\n",
    "import misc_functions as misc\n",
    "\n",
    "import os\n",
    "\n",
    "if not os.path.exists(\"net\"):\n",
    "    os.makedirs(\"net\")\n",
    "if not os.path.exists(\"results\"):\n",
    "    os.makedirs(\"results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "################  CONSTANTS  ################\n",
    "#############################################\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "DIM_L_EMBED = 10 # embedding dimension of positional embedding\n",
    "\n",
    "LR = 1e-3\n",
    "UPDATE_STEPS_PER_EPOCH = 100\n",
    "ITERATION_MULTIPLIER = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################\n",
    "##################  PRECOMPUTATIONS  #################\n",
    "######################################################\n",
    "\n",
    "# 1. Learn a continuous representation of the image\n",
    "def learn_continuous_image_representation(img, grid, SCENE, ITS_INITIAL):\n",
    "    param_net = models.Energy2D(dim_l_embed=DIM_L_EMBED).to(DEVICE)\n",
    "    optimiser = torch.optim.Adam(param_net.parameters(), lr=LR)\n",
    "\n",
    "    tensor_rgb = img.view(3, -1).transpose(0,1).to(DEVICE)\n",
    "    tensor_pos = grid.view(2, -1).transpose(0,1).to(DEVICE)\n",
    "\n",
    "    if os.path.isfile(\"net/\"+SCENE+\"_\"+str(int(STRETCH_FACTOR*100.))+\"_continuous_representation.net\"):\n",
    "        param_net.load_state_dict(torch.load(\"net/\"+SCENE+\"_\"+str(int(STRETCH_FACTOR*100.))+\"_continuous_representation.net\"))\n",
    "        return param_net\n",
    "    for _ in tqdm(range(ITS_INITIAL)):\n",
    "        for _ in range(UPDATE_STEPS_PER_EPOCH):\n",
    "            optimiser.zero_grad()\n",
    "            \n",
    "            offset_out = param_net(tensor_pos)\n",
    "            loss = (offset_out - tensor_rgb).square().mean()\n",
    "\n",
    "            loss.backward()\n",
    "            optimiser.step()\n",
    "    \n",
    "    # Save network\n",
    "    torch.save(param_net.state_dict(), \"net/\"+SCENE+\"_\"+str(int(STRETCH_FACTOR*100.))+\"_continuous_representation.net\")\n",
    "    \n",
    "    return param_net\n",
    "\n",
    "# 2.1. Learn the initial deformation\n",
    "def learn_initial_deformation_net(tensor_pos, stretched_pos_train, ITS_DEFORM):\n",
    "    deform_net = models.Deform2d(dim_l_embed=DIM_L_EMBED).to(DEVICE)\n",
    "    optimiser = torch.optim.Adam(deform_net.parameters(), lr=LR)\n",
    "\n",
    "    if os.path.isfile(\"net/\"+SCENE+\"_\"+str(int(STRETCH_FACTOR*100.))+\"_initial_deform.net\"):\n",
    "        deform_net.load_state_dict(torch.load(\"net/\"+SCENE+\"_\"+str(int(STRETCH_FACTOR*100.))+\"_initial_deform.net\"))\n",
    "        return deform_net\n",
    "    for _ in tqdm(range(ITS_DEFORM)):\n",
    "        for _ in range(UPDATE_STEPS_PER_EPOCH):\n",
    "            optimiser.zero_grad()\n",
    "\n",
    "            deformed_pos = stretched_pos_train.clone()\n",
    "            offset_out = deform_net(deformed_pos)\n",
    "            deformed_pos[:,1:] += offset_out\n",
    "            loss = (deformed_pos - tensor_pos).square().mean()\n",
    "            \n",
    "            loss.backward()\n",
    "            optimiser.step()\n",
    "    \n",
    "    # Output final visualization of the initial deformation and save network\n",
    "    torch.save(deform_net.state_dict(), \"net/\"+SCENE+\"_\"+str(int(STRETCH_FACTOR*100.))+\"_initial_deform.net\")\n",
    "    \n",
    "    return deform_net\n",
    "\n",
    "# 2.2. Learn the cumulative energy.\n",
    "def learn_cumulative_energy(cumsum_grd, stretched_pos_train, ITS_INITIAL):\n",
    "    cumgrad_net = models.Deform2d(dim_l_embed=DIM_L_EMBED).to(DEVICE)\n",
    "    optimiser_cumgrad_net = torch.optim.Adam(cumgrad_net.parameters(), lr=0.0001)\n",
    "    \n",
    "    pts_for_cumgrad = stretched_pos_train.clone().to(DEVICE)\n",
    "    pts_for_cumgrad[:,1] /= STRETCH_FACTOR\n",
    "\n",
    "    if os.path.isfile(\"net/\"+SCENE+\"_\"+str(int(STRETCH_FACTOR*100.))+\"_cumgrad.net\"):\n",
    "        cumgrad_net.load_state_dict(torch.load(\"net/\"+SCENE+\"_\"+str(int(STRETCH_FACTOR*100.))+\"_cumgrad.net\"))\n",
    "        return cumgrad_net\n",
    "    for _ in tqdm(range(ITS_INITIAL)):\n",
    "        for _ in range(UPDATE_STEPS_PER_EPOCH):\n",
    "            optimiser_cumgrad_net.zero_grad()\n",
    "            \n",
    "            cumsum_out = cumgrad_net(pts_for_cumgrad.clone())\n",
    "            loss = (cumsum_out - cumsum_grd.view(-1)[:,None]).square().mean()\n",
    "\n",
    "            loss.backward()\n",
    "            optimiser_cumgrad_net.step()\n",
    "        \n",
    "    # Save network\n",
    "    torch.save(cumgrad_net.state_dict(), \"net/\"+SCENE+\"_\"+str(int(STRETCH_FACTOR*100.))+\"_cumgrad.net\")\n",
    "\n",
    "    return cumgrad_net\n",
    "\n",
    "# Precompute the initial network required to optimise the final deformation.\n",
    "def precomputations(img, ITS_INITIAL, ITS_DEFORM):\n",
    "    grid = torch.ones(2, img.size()[1], img.size()[2])\n",
    "    strip_a = torch.linspace(0, img.size()[1]-1, img.size()[1])[:,None] / img.size()[1]\n",
    "    strip_b = torch.linspace(0, img.size()[2]-1, img.size()[2])[None,:] / img.size()[2]\n",
    "    grid[0] = grid[0] * strip_a\n",
    "    grid[1] = grid[1] * strip_b\n",
    "    tensor_pos = grid.view(2, -1).transpose(0,1).to(DEVICE)\n",
    "\n",
    "    DIM_1 = img.size()[1]\n",
    "    DIM_2 = img.size()[2]\n",
    "    DIM_2_TEST = int(DIM_2 * STRETCH_FACTOR)\n",
    "\n",
    "    ##############################################\n",
    "    ### STEP 1. - INITIALISE & LEARN IMAGE NET ###\n",
    "    ##############################################\n",
    "    print(\"*** STEP 1: LEARN CONTINUOUS IMAGE REPRESENTATION ***\")\n",
    "    \n",
    "    param_net = learn_continuous_image_representation(img, grid, SCENE, ITS_INITIAL)\n",
    "    \n",
    "    print(\"*** DONE WITH LEARNING THE IMAGE ***\")\n",
    "    \n",
    "    # Render intermediate visualization\n",
    "    with torch.no_grad():\n",
    "        test_img = param_net(tensor_pos).transpose(0,1).view(3, DIM_1, DIM_2).cpu()\n",
    "        \n",
    "    if VISUALIZE:\n",
    "        misc.show(test_img)\n",
    "    \n",
    "    dir_name = \"results/\"+SCENE+\"_\"+str(int(STRETCH_FACTOR*100.))+\"_continuous_representation.png\"\n",
    "    save_image(test_img, dir_name)\n",
    "    print(\"- Rendered continuous image representation was saved under \", dir_name)\n",
    "\n",
    "    ##############################################\n",
    "    ### STEP 2.1. - INITIALISE DEFORMATION NET ###\n",
    "    ##############################################\n",
    "\n",
    "    # Input samples for the deformed net; but as many input samples as deformed.\n",
    "    strip_a = torch.linspace(0, DIM_1-1, DIM_1)[:,None] / DIM_1\n",
    "    strip_b = torch.linspace(0, DIM_2-1, int(DIM_2))[None,:] / DIM_2\n",
    "    grid_test = torch.ones(2, img.size()[1], int(DIM_2))\n",
    "    grid_test[0] = grid_test[0] * strip_a                  # e.g. [0.0, 1.0]\n",
    "    grid_test[1] = grid_test[1] * strip_b * STRETCH_FACTOR # e.g. [0.0, 0.5]\n",
    "    stretched_pos_train = grid_test.view(2, -1).transpose(0,1).to(DEVICE)\n",
    "\n",
    "    # Initialise samples on which we regularise.\n",
    "    strip_a = torch.linspace(0, DIM_1-1, DIM_1)[:,None] / DIM_1\n",
    "    strip_b = torch.linspace(0, DIM_2_TEST-1, int(DIM_2_TEST))[None,:] / DIM_2_TEST\n",
    "    grid_test = torch.ones(2, img.size()[1], int(DIM_2_TEST))\n",
    "    grid_test[0] = grid_test[0] * strip_a                  # e.g. [0.0, 1.0]\n",
    "    grid_test[1] = grid_test[1] * strip_b * STRETCH_FACTOR # e.g. [0.0, 0.5]\n",
    "    stretched_pos_test = grid_test.view(2, -1).transpose(0,1).to(DEVICE)\n",
    "\n",
    "    strip_a = torch.linspace(-1, DIM_1, DIM_1 + 2)[:,None] / DIM_1\n",
    "    strip_b = torch.linspace(-1, DIM_2_TEST, DIM_2_TEST + 2)[None,:] / DIM_2_TEST\n",
    "    grid_test = torch.ones(2, img.size()[1] + 2, DIM_2_TEST + 2)\n",
    "    grid_test[0] = grid_test[0] * strip_a                  # e.g. [0.0, 1.0]\n",
    "    grid_test[1] = grid_test[1] * strip_b * STRETCH_FACTOR # e.g. [0.0, 0.5]\n",
    "    \n",
    "    #--------------------------------------------\n",
    "    \n",
    "    print(\"*** STEP 2.1: LEARN THE INITIAL DEFORMATION ***\")\n",
    "    \n",
    "    deform_net = learn_initial_deformation_net(tensor_pos, stretched_pos_train, ITS_DEFORM)\n",
    "    \n",
    "    print(\"*** DONE WITH LEARNING THE INITAL DEFORMATION ***\")\n",
    "    \n",
    "    # Render intermediate visualization\n",
    "    with torch.no_grad():\n",
    "        deformed_positions = deform_net(stretched_pos_test)\n",
    "        pos = stretched_pos_test.clone()\n",
    "        pos[:,1:] += deformed_positions\n",
    "        deformed_positions = pos\n",
    "        test_img = param_net(deformed_positions).transpose(0,1).view(3, DIM_1, DIM_2_TEST).cpu()\n",
    "        \n",
    "    if VISUALIZE:\n",
    "        misc.show(test_img)\n",
    "    \n",
    "    dir_name = \"results/\"+SCENE+\"_\"+str(int(STRETCH_FACTOR*100.))+\"_initial_deform.png\"\n",
    "    save_image(test_img, dir_name)\n",
    "    print(\"- Initially deformed image was saved under \", dir_name)\n",
    "\n",
    "    ##################################################\n",
    "    ### STEP 2.2. - LEARN INITAL CUMULATIVE ENERGY ###\n",
    "    ##################################################\n",
    "  \n",
    "    # Compute ground turth cumulative energy via image gradient.\n",
    "    grd = misc.gradient(img)\n",
    "    cumsum_grd = torch.cumsum(grd, 1)\n",
    "    cumsum_grd /= cumsum_grd.size()[1]\n",
    "    cumsum_grd = cumsum_grd.to(DEVICE)\n",
    "    cumsum_grd /= cumsum_grd.max()\n",
    "    \n",
    "    #--------------------------------------------\n",
    "    \n",
    "    print(\"*** STEP 2.2: LEARN THE INITIAL CUMULATIVE ENERGY ***\")\n",
    "    \n",
    "    cumgrad_net = learn_cumulative_energy(cumsum_grd, stretched_pos_train, ITS_INITIAL)\n",
    "    \n",
    "    print(\"*** DONE WITH LEARNING THE INITAL CUMULATIVE ENERGY ***\")\n",
    "    \n",
    "    # Render intermediate visualization\n",
    "    with torch.no_grad():\n",
    "        pts_for_cumgrad = stretched_pos_train.clone().to(DEVICE)\n",
    "        pts_for_cumgrad[:,1] /= STRETCH_FACTOR\n",
    "        cumgrad_out = cumgrad_net(pts_for_cumgrad.clone())\n",
    "        test_img = cumgrad_out.view(1, DIM_1, DIM_2).cpu().repeat(3,1,1)\n",
    "        test_img -= test_img.min()\n",
    "        test_img /= test_img.max()\n",
    "\n",
    "    if VISUALIZE:\n",
    "        misc.show(test_img)\n",
    "        \n",
    "    dir_name = \"results/\"+SCENE+\"_\"+str(int(STRETCH_FACTOR*100.))+\"_cumgrad.png\"\n",
    "    save_image(test_img, dir_name)\n",
    "    print(\"- Cumulative energy visualization was saved under \", dir_name)\n",
    "\n",
    "    return param_net, deform_net, cumgrad_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "##################  METHOD  #################\n",
    "#############################################\n",
    "\n",
    "def monotonicity_loss(deform_net, stretched_pos_test, STRETCH_FACTOR, OAX):\n",
    "    tensor_pos_a = stretched_pos_test.clone()\n",
    "    tensor_pos_b = stretched_pos_test.clone()\n",
    "    offset = torch.rand_like(tensor_pos_b) * 0.05 + 0.0025\n",
    "    offset[:,OAX] = 0.0\n",
    "    tensor_pos_b += offset\n",
    "\n",
    "    offset_a = deform_net(tensor_pos_a)\n",
    "    offset_b = deform_net(tensor_pos_b)\n",
    "    \n",
    "    if STRETCH_FACTOR < 1.0: # shrinkage\n",
    "        # make sure the further right we go in the image, the more offset we have\n",
    "        # i.e. point more to the left should ALWAYS be smaller than the one on it's right\n",
    "        loss_mono  = torch.nn.functional.relu(offset_a - offset_b).mean()\n",
    "    elif STRETCH_FACTOR > 1.0: # expanding\n",
    "        loss_mono = torch.nn.functional.relu(offset_b - offset_a).mean()\n",
    "        loss_mono += torch.nn.functional.relu(offset_a).mean() # no positive values, only allow starting at 0 deformation\n",
    "    else: # no mono loss for editing (=same size)\n",
    "        loss_mono = torch.zeros(1, device=DEVICE).mean()\n",
    "        \n",
    "    return loss_mono\n",
    "  \n",
    "def boundary_loss(deform_net, STRETCH_FACTOR, stretched_pos_test, AX):  \n",
    "    input_left = stretched_pos_test.clone()\n",
    "    input_left[:,1] = 0.0\n",
    "    target_left = torch.zeros_like(input_left[:,AX:(AX+1)])\n",
    "\n",
    "    # all the way to the right\n",
    "    input_right = stretched_pos_test.clone()\n",
    "    input_right[:,1] = STRETCH_FACTOR\n",
    "    target_right = 1.0 - STRETCH_FACTOR\n",
    "\n",
    "    loss_boundaries  = (deform_net(input_left)  - target_left ).square().mean()\n",
    "    loss_boundaries += (deform_net(input_right) - target_right).square().mean()\n",
    "    \n",
    "    return loss_boundaries\n",
    "\n",
    "def gradient_flow(deform_net, param_net, cumgrad_net, stretched_pos_test, STRETCH_FACTOR, AX, OAX, DISTANCE_FOR_GRADIENT, DIM_1, DIM_2_TEST, loss_boundaries):\n",
    "    loss_gradients = 0.0\n",
    "\n",
    "    pt_x = stretched_pos_test.clone() # in [0,1] for dim 0, in [0,0.5] for dim 1\n",
    "    pt_x_eps = pt_x.clone()\n",
    "    pt_x_eps[:,AX:(AX+1)] += DISTANCE_FOR_GRADIENT\n",
    "\n",
    "    offset_pt_x = deform_net(pt_x.clone())\n",
    "    D_pt_x = pt_x.clone()\n",
    "    D_pt_x[:,AX:(AX+1)] += offset_pt_x.clone()\n",
    "    \n",
    "    D_pt_x_eps = pt_x_eps.clone()\n",
    "    offset_pt_x_eps = deform_net(D_pt_x_eps.clone())\n",
    "    D_pt_x_eps[:,AX:(AX+1)] += offset_pt_x_eps\n",
    "\n",
    "    if STRETCH_FACTOR > 1.0: # expansion: fix boundary losses\n",
    "        offsets = D_pt_x[:,AX]\n",
    "        smaller = offsets < 0.0\n",
    "        if offsets[smaller].size()[0] > 0:\n",
    "            loss_boundaries += -offsets[smaller].sum() / offsets.size()[0]\n",
    "        bigger = offsets > 1.0\n",
    "        if offsets[bigger].size()[0] > 0:\n",
    "            loss_boundaries += offsets[bigger].sum() / offsets.size()[0]\n",
    "    \n",
    "    D_pt_x_eps = D_pt_x_eps.clamp(0.0, 1.0)\n",
    "    D_pt_x = D_pt_x.clamp(0.0, 1.0)\n",
    "\n",
    "    energy = torch.abs(cumgrad_net(D_pt_x_eps.clone()) - cumgrad_net(D_pt_x.clone()))[:,0].detach()\n",
    "    \n",
    "    if STRETCH_FACTOR > 1.0: # expansion: punish LOCAL gradient, no need for integral stuff (we can't jump over things)\n",
    "        D_pt_eps_x = D_pt_x.clone()\n",
    "        D_pt_eps_x2 = D_pt_x.clone()\n",
    "        D_pt_eps_x3 = D_pt_x.clone()\n",
    "        D_pt_eps_x4 = D_pt_x.clone()\n",
    "        D_pt_eps_x[:,AX:(AX+1)] += DISTANCE_FOR_GRADIENT\n",
    "        D_pt_eps_x2[:,AX:(AX+1)] -= DISTANCE_FOR_GRADIENT\n",
    "        D_pt_eps_x3[:,OAX:(OAX+1)] += DISTANCE_FOR_GRADIENT\n",
    "        D_pt_eps_x4[:,OAX:(OAX+1)] -= DISTANCE_FOR_GRADIENT\n",
    "        energy  = ((param_net(D_pt_eps_x.clone()) - param_net(D_pt_x.clone())).square().sum(-1).abs() + 0.000001).sqrt().detach()\n",
    "        energy += ((param_net(D_pt_eps_x2.clone()) - param_net(D_pt_x.clone())).square().sum(-1).abs() + 0.000001).sqrt().detach()\n",
    "        energy += ((param_net(D_pt_eps_x3.clone()) - param_net(D_pt_x.clone())).square().sum(-1).abs() + 0.000001).sqrt().detach()\n",
    "        energy += ((param_net(D_pt_eps_x4.clone()) - param_net(D_pt_x.clone())).square().sum(-1).abs() + 0.000001).sqrt().detach()\n",
    "        energy /= 4.0\n",
    "\n",
    "    \n",
    "    offset_1 = deform_net(pt_x.clone())\n",
    "    offset_2 = deform_net(pt_x_eps.clone())\n",
    "    deformation_magnitude = (offset_1 - offset_2).abs().sum(dim=1)\n",
    "    \n",
    "    energy = energy.view(DIM_1, DIM_2_TEST)\n",
    "    loss_gradients = (deformation_magnitude.view(DIM_1, DIM_2_TEST) * energy.clone()).mean()\n",
    "\n",
    "    # make sure we do include the diff between last piece <-> end of item\n",
    "    fringe = stretched_pos_test.view(DIM_1, DIM_2_TEST, 2)[:, -1, :].clone()\n",
    "    boundary = torch.ones_like(fringe)\n",
    "    boundary[:,AX] = STRETCH_FACTOR\n",
    "\n",
    "    offset_1 = deform_net(fringe.clone())\n",
    "    offset_2 = deform_net(boundary.clone())\n",
    "\n",
    "    D_fringe = fringe.clone()\n",
    "    D_fringe[:,AX:(AX+1)] += offset_1\n",
    "    D_boundary = boundary.clone()\n",
    "    D_boundary[:,AX:(AX+1)] += offset_2\n",
    "\n",
    "    deformation_magnitude_fringe = (offset_1 - offset_2).abs().sum(dim=1)\n",
    "    energy_fringe = torch.abs(cumgrad_net(D_boundary.clone()) - cumgrad_net(D_fringe.clone()))[:,0].detach()\n",
    "    energy_fringe *= 10.0\n",
    "\n",
    "    impact = 1.0 / DIM_1\n",
    "    loss_gradients += (deformation_magnitude_fringe * energy_fringe).mean() * impact\n",
    "\n",
    "    # for shearing, only take colour gradient\n",
    "    D_pt_eps_x = D_pt_x.clone()\n",
    "    D_pt_eps_x[:,AX:(AX+1)] += DISTANCE_FOR_GRADIENT\n",
    "    energy = ((param_net(D_pt_eps_x.clone()) - param_net(D_pt_x.clone())).square().sum(-1).abs() + 0.000001).sqrt().detach().view(DIM_1, DIM_2_TEST)\n",
    "    \n",
    "    energy_for_shearing = energy.clone()\n",
    "    \n",
    "    return energy_for_shearing, loss_gradients, loss_boundaries\n",
    "\n",
    "def shearing_loss(deform_net, stretched_pos_test, OAX, DISTANCE_FOR_GRADIENT, DIM_1, DIM_2_TEST, energy_for_shearing):\n",
    "    loss_shearing = torch.zeros(1, device=DEVICE)\n",
    "\n",
    "    # 1. Get points.\n",
    "    pt_x = stretched_pos_test.clone()\n",
    "    pt_y = pt_x.clone()\n",
    "    pt_y[:,OAX:(OAX+1)] += DISTANCE_FOR_GRADIENT\n",
    "\n",
    "    # 2. Get their offset on y-axis.\n",
    "    D_pt_x = pt_x.clone()\n",
    "    D_pt_y = pt_y.clone()\n",
    "    offset_x = deform_net(D_pt_x.clone())\n",
    "    offset_y = deform_net(D_pt_y.clone())\n",
    "    diff = (offset_x - offset_y).abs()\n",
    "    \n",
    "    diff = diff.view(DIM_1, DIM_2_TEST).contiguous()\n",
    "    diff = diff * energy_for_shearing\n",
    "\n",
    "    loss_shearing = diff.mean()\n",
    "    \n",
    "    return loss_shearing\n",
    "\n",
    "def continuous_seam_carve(img, STRETCH_FACTOR, ITS_INITIAL, ITS_DEFORM, ITS_OPTIM):\n",
    "    DISTANCE_FOR_GRADIENT = 0.01\n",
    "    #stretch factor:\n",
    "    #    1 = original size\n",
    "    #  0.5 = half size\n",
    "    #    2 = double the size\n",
    "    DIM_1 = img.size()[1]\n",
    "    DIM_2 = img.size()[2]\n",
    "    DIM_2_TEST = int(DIM_2 * STRETCH_FACTOR)\n",
    "    \n",
    "    ######################################################\n",
    "    ### STEP 1-2 - PRECOMPUTE ALL THE INITIAL NETWORKS ###\n",
    "    ######################################################\n",
    "    \n",
    "    param_net, deform_net, cumgrad_net = precomputations(img, ITS_INITIAL, ITS_DEFORM)\n",
    "    \n",
    "    cumgrad_net.train(False)\n",
    "    param_net.train(False)\n",
    "\n",
    "    #############################################\n",
    "    ### STEP 3 - OPTIMISE DEFORMATION NETWORK ###\n",
    "    #############################################\n",
    "    \n",
    "    # Initialise samples on which we regularise.\n",
    "    strip_a = torch.linspace(0, DIM_1-1, DIM_1)[:,None] / DIM_1\n",
    "    strip_b = torch.linspace(0, DIM_2_TEST-1, int(DIM_2_TEST))[None,:] / DIM_2_TEST\n",
    "    grid_test = torch.ones(2, img.size()[1], int(DIM_2_TEST))\n",
    "    grid_test[0] = grid_test[0] * strip_a                  # e.g. [0.0, 1.0]\n",
    "    grid_test[1] = grid_test[1] * strip_b * STRETCH_FACTOR # e.g. [0.0, 0.5]\n",
    "    stretched_pos_test = grid_test.view(2, -1).transpose(0,1).to(DEVICE)\n",
    "\n",
    "    AX = 1\n",
    "    OAX = 0\n",
    "    \n",
    "    print(\"*** STEP 3: OPTIMISE DEFORMATION ***\")\n",
    "    \n",
    "    optimiser = torch.optim.AdamW(deform_net.parameters(), lr=0.001, weight_decay=0.0, amsgrad=True)\n",
    "\n",
    "    best_image = None\n",
    "    best_loss  = None\n",
    "\n",
    "    if STRETCH_FACTOR > 1.0:\n",
    "        ITS_OPTIM = int(ITS_OPTIM * 0.5)\n",
    "        \n",
    "    for epoch in tqdm(range(ITS_OPTIM)):\n",
    "        avg_loss = 0.0\n",
    "\n",
    "        avg_loss_mono       = 0.0\n",
    "        avg_loss_boundaries = 0.0\n",
    "        avg_loss_gradients  = 0.0\n",
    "        avg_loss_shearing   = 0.0\n",
    "        avg_loss_cap        = 0.0\n",
    "\n",
    "        loss_amp = 1.0\n",
    "        # decay LR last few iterations\n",
    "        if epoch > int(ITS_OPTIM * 0.75):\n",
    "            loss_amp = (ITS_OPTIM - epoch) / ITS_OPTIM * 4.0\n",
    "        \n",
    "        lambdas = dict()\n",
    "\n",
    "        lambdas['mono']   =  10000.0\n",
    "        lambdas['bound']  =  10000.0\n",
    "        lambdas['grad']   =  1000.0\n",
    "        lambdas['shear']  =    250.0\n",
    "        lambdas['cap']    = 100000.0\n",
    "        \n",
    "        for s in range(UPDATE_STEPS_PER_EPOCH):\n",
    "            optimiser.zero_grad()\n",
    "\n",
    "            ### MONOTONICITY ###\n",
    "            loss_mono = monotonicity_loss(deform_net, \n",
    "                                          stretched_pos_test, \n",
    "                                          STRETCH_FACTOR, \n",
    "                                          OAX)\n",
    "            ### MONOTONICITY ###\n",
    "\n",
    "            ### BOUNDARIES ###\n",
    "            loss_boundaries = boundary_loss(deform_net, \n",
    "                                            STRETCH_FACTOR, \n",
    "                                            stretched_pos_test, \n",
    "                                            AX)\n",
    "            ### BOUNDARIES ###\n",
    "\n",
    "            ### GRADIENT FLOW CONTROL ###\n",
    "            energy_for_shearing, loss_gradients, loss_boundaries = gradient_flow(deform_net,\n",
    "                                                                                 param_net,\n",
    "                                                                                 cumgrad_net,\n",
    "                                                                                 stretched_pos_test,\n",
    "                                                                                 STRETCH_FACTOR,\n",
    "                                                                                 AX,\n",
    "                                                                                 OAX,\n",
    "                                                                                 DISTANCE_FOR_GRADIENT,\n",
    "                                                                                 DIM_1,\n",
    "                                                                                 DIM_2_TEST,\n",
    "                                                                                 loss_boundaries)\n",
    "            ### GRADIENT FLOW CONTROL ###\n",
    "            \n",
    "            ### SHEARING ###\n",
    "            loss_shearing = shearing_loss(deform_net,\n",
    "                                          stretched_pos_test,\n",
    "                                          OAX,\n",
    "                                          DISTANCE_FOR_GRADIENT,\n",
    "                                          DIM_1,\n",
    "                                          DIM_2_TEST,\n",
    "                                          energy_for_shearing)\n",
    "            ### SHEARING ###\n",
    "\n",
    "            ### CAP DEFORMATION FOR EXPANSION ###\n",
    "            loss_cap = torch.zeros(1, device=DEVICE).mean()\n",
    "            if STRETCH_FACTOR > 1.0:\n",
    "                pt_x = stretched_pos_test.clone() # in [0,1] for dim 0, in [0,0.5] for dim 1\n",
    "                pt_x_eps = pt_x.clone()\n",
    "                max_dist = max(1.0 / DIM_2_TEST, 1.0 / DIM_2)\n",
    "                DISTANCE_VALUES = max_dist * 1.1 * torch.rand(pt_x.size()[0], device=DEVICE) + 0.0000001\n",
    "                pt_x_eps[:,AX] += DISTANCE_VALUES\n",
    "\n",
    "                offset_pt_x = deform_net(pt_x.clone()).view(-1)\n",
    "                offset_pt_x_eps = deform_net(pt_x_eps.clone()).view(-1)\n",
    "\n",
    "                loss_cap = torch.nn.functional.relu((offset_pt_x - offset_pt_x_eps) - DISTANCE_VALUES * .75)\n",
    "                \n",
    "                loss_cap = loss_cap.mean()\n",
    "            ### CAP DEFORMATION FOR EXPANSION ###\n",
    "\n",
    "            # Putting everything together.\n",
    "            loss = loss_mono * lambdas['mono'] + loss_boundaries * lambdas['bound'] + loss_gradients * lambdas['grad'] + loss_shearing * lambdas['shear']\n",
    "            if STRETCH_FACTOR > 1.0:\n",
    "                loss += loss_cap * lambdas['cap']\n",
    "                \n",
    "            loss = loss * loss_amp\n",
    "\n",
    "            avg_loss_mono += loss_mono.item()\n",
    "            avg_loss_boundaries += loss_boundaries.item()\n",
    "            avg_loss_gradients += loss_gradients.item()\n",
    "            avg_loss_shearing += loss_shearing.item()\n",
    "            avg_loss_cap += loss_cap.item()\n",
    "            \n",
    "            avg_loss += loss.item()\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            if epoch == 0:\n",
    "                optimiser.zero_grad()\n",
    "                break\n",
    "            optimiser.step()\n",
    "\n",
    "        # Keep track of the best image and net\n",
    "        if (best_loss == None or avg_loss < best_loss) or epoch == 1:\n",
    "            best_loss = avg_loss\n",
    "            best_image = misc.output_deformed_image(deform_net, param_net, stretched_pos_test, DIM_1, DIM_2_TEST)\n",
    "            torch.save(deform_net.state_dict(), \"net/\"+SCENE+\"_\"+str(int(STRETCH_FACTOR*100.))+\"_optimized_deform.net\")\n",
    "\n",
    "    print(\"*** DONE WITH OPTIMISING DEFORMATION ***\")\n",
    "    return best_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "###################  MAIN  ##################\n",
    "#############################################\n",
    "\n",
    "def resize_image(img, factor_x, factor_y = 1.0):\n",
    "    height = int(img.shape[0] // DOWNSCALE_FACTOR)\n",
    "    width = int(img.shape[1] // DOWNSCALE_FACTOR)\n",
    "    img = Image.fromarray(img).convert(\"RGBA\")\n",
    "    img = img.resize((width, height), Image.Resampling.LANCZOS)\n",
    "    img = torch.tensor(np.array(img)).transpose(1,2).transpose(1,0).float()[0:3] / 255.0\n",
    "\n",
    "    if factor_x != 1.0 or (factor_x == 1.0 and factor_y == 1.0):\n",
    "        result = continuous_seam_carve(img=img,\n",
    "                                       STRETCH_FACTOR=factor_x,\n",
    "                                       ITS_INITIAL=int(2 * 50 * ITERATION_MULTIPLIER),\n",
    "                                       ITS_DEFORM=int(20 * ITERATION_MULTIPLIER),\n",
    "                                       ITS_OPTIM=int(100 * ITERATION_MULTIPLIER))\n",
    "    if factor_y != 1.0:\n",
    "        result = continuous_seam_carve(img=img.transpose(1,2).contiguous(),\n",
    "                                       STRETCH_FACTOR=factor_y,\n",
    "                                       ITS_INITIAL=int(2 * 50 * ITERATION_MULTIPLIER), \n",
    "                                       ITS_DEFORM=int(20 * ITERATION_MULTIPLIER), \n",
    "                                       ITS_OPTIM=int(100 * ITERATION_MULTIPLIER))\n",
    "        result = result.transpose(1,2).contiguous()\n",
    "        \n",
    "    return result\n",
    "\n",
    "# -----------------------------------------\n",
    "\n",
    "try:\n",
    "    img = imageio.v2.imread(\"scenes/\"+SCENE+\".jpg\")\n",
    "except:\n",
    "    img = imageio.v2.imread(\"scenes/\"+SCENE+\".png\")\n",
    "\n",
    "result = resize_image(img, STRETCH_FACTOR, 1.0)\n",
    "\n",
    "if VISUALIZE:\n",
    "    misc.show(result)\n",
    "    \n",
    "dir_name = \"results/\"+SCENE+\"_\"+str(int(STRETCH_FACTOR*100.))+\"_final_deform.png\"\n",
    "save_image(result, dir_name)\n",
    "print(\"- The final deformed image was saved under \", dir_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('ldm')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "762d0aacbb96145e3e0a572e635abc9d34fc879add3d0a8bee876d5c9e02b870"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
